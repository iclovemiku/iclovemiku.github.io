<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>mikufans</title>
    <description>在读研究生,研究摸鱼,摸鱼,摸鱼.</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Wed, 29 Mar 2023 11:41:44 +0800</pubDate>
    <lastBuildDate>Wed, 29 Mar 2023 11:41:44 +0800</lastBuildDate>
    <generator>Jekyll v4.3.2</generator>
    
      <item>
        <title>高斯混合模型详解</title>
        <description>&lt;h1 id=&quot;高斯混合模型&quot;&gt;高斯混合模型&lt;/h1&gt;

&lt;p&gt;当我们面对一个复杂的数据集时，我们可能需要使用一种能够描述这些数据集中不同分布的模型。高斯混合模型（Gaussian Mixture Model，GMM）就是一种流行的用于建模多个高斯分布混合的概率模型。在本文中，我们将学习高斯混合模型的原理、如何使用 EM 算法进行参数估计，以及如何使用 Python 中的 Scikit-learn 库实现高斯混合模型。&lt;/p&gt;

&lt;h2 id=&quot;高斯混合模型原理&quot;&gt;高斯混合模型原理&lt;/h2&gt;

&lt;p&gt;高斯混合模型是一种概率模型，用于描述由多个高斯分布混合而成的数据分布。我们可以用以下公式来表示一个高斯混合模型：
\(p(x)=\sum^K_{k=1}\pi_k\mathcal{N}(x|\mu_k,\Sigma_k)\)
其中 $x$ 表示数据点，$K$ 表示高斯分布的数量，$\pi_k$ 表示第 $k$ 个高斯分布的权重，$\mu_k$ 和 $\Sigma_k$ 分别表示第 $k$ 个高斯分布的均值和协方差矩阵，$\mathcal{N}(x|\mu_k,\Sigma_k)$ 表示以 $\mu_k$ 为均值，$\Sigma_k$ 为协方差矩阵的高斯分布的概率密度函数。&lt;/p&gt;

&lt;p&gt;可以看出，高斯混合模型将数据分布建模为多个高斯分布的混合。每个高斯分布都由其均值和协方差矩阵来确定。模型的参数包括每个高斯分布的权重和每个高斯分布的均值和协方差矩阵。&lt;/p&gt;

&lt;h2 id=&quot;使用-em-算法进行参数估计&quot;&gt;使用 EM 算法进行参数估计&lt;/h2&gt;

&lt;p&gt;如何确定高斯混合模型中每个高斯分布的参数呢？这个问题可以通过使用 EM 算法来解决。EM 算法是一种迭代算法，它用于在含有隐变量的概率模型中进行参数估计。高斯混合模型中的隐变量是每个数据点属于哪个高斯分布。&lt;/p&gt;

&lt;p&gt;EM 算法包括两个步骤：E 步骤和 M 步骤。在 E 步骤中，我们计算每个数据点属于每个高斯分布的概率。在 M 步骤中，我们使用这些概率来更新高斯分布的参数。重复执行这两个步骤，直到模型参数收敛。&lt;/p&gt;

&lt;p&gt;具体地，我们可以按照以下步骤来实现高斯混合模型的 EM 算法：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;初始化每个高斯分布的权重 $\pi_k$、&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;均值 $\mu_k$ 和协方差矩阵 $\Sigma_k$。&lt;/p&gt;

    &lt;p&gt;在 E 步骤中，对于每个数据点 $x_i$，计算其属于每个高斯分布的后验概率 $w_{ik}$，即：
\(w_{i k}=\frac{\pi_{k} \mathcal{N}\left(x_{i} \mid \mu_{k}, \Sigma_{k}\right)}{\sum_{j=1}^{K} \pi_{j} \mathcal{N}\left(x_{i} \mid \mu_{j}, \Sigma_{j}\right)}\)
其中 $w_{ik}$ 表示数据点 $x_i$ 属于第 $k$ 个高斯分布的后验概率。&lt;/p&gt;

    &lt;p&gt;在 M 步骤中，对于每个高斯分布，更新其权重、均值和协方差矩阵：
\(\pi_k=\frac{1}{N}\sum_{i=1}^{N}w_{ik}\\
u_k=\frac{\sum_{i=1}^Nw_{ik}x_i}{\sum^N_{i=1}w_{ik}}\\
\Sigma_k= \frac{\sum^N_{i=1}w_{ik}(x_i-u_k)(x_i-u_k)^T}{\sum^N_{i=1}w_{ik}}\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;其中 $N$ 表示数据点的数量，$\pi_k$ 表示第 $k$ 个高斯分布的权重，$\mu_k$ 和 $\Sigma_k$ 分别表示第 $k$ 个高斯分布的均值和协方差矩阵。&lt;/p&gt;

&lt;p&gt;重复执行 E 步骤和 M 步骤，直到模型参数收敛。&lt;/p&gt;

&lt;h2 id=&quot;实现高斯混合模型&quot;&gt;实现高斯混合模型&lt;/h2&gt;

&lt;p&gt;现在我们来使用 Python 中的 Scikit-learn 库来实现高斯混合模型。我们首先需要生成一个带有多个高斯分布的数据集：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sklearn.datasets&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make_blobs&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 生成带有 3 个高斯分布的数据集
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;make_blobs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;然后，我们可以使用 Scikit-learn 中的 GaussianMixture 类来拟合高斯混合模型并进行预测：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from sklearn.mixture import GaussianMixture

# 创建 GaussianMixture 对象
gmm = GaussianMixture(n_components=3, random_state=42)

# 拟合模型并进行预测
gmm.fit(X)
y_pred = gmm.predict(X)

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;最后，我们可以可视化模型的结果：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import matplotlib.pyplot as plt

# 绘制数据点
plt.scatter(X[:, 0], X[:, 1], c=y_pred)
plt.show()

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这样就可以得到一个带有不同颜色的数据点的散点图，每种颜色代表一个高斯分布。我们可以看到，高斯混合模型成功地将数据集分成了三个簇。&lt;/p&gt;

&lt;h2 id=&quot;结论&quot;&gt;结论&lt;/h2&gt;

&lt;p&gt;高斯混合模型是一种强大的聚类方法，可以识别多个高斯分布并将数据集分成多个簇。在实践中，高斯混合模型通常比传统的 K 均值聚类更具有优势，因为它可以更好地处理非球形、重叠和不均衡的数据集。&lt;/p&gt;

&lt;p&gt;在本文中，我们介绍了高斯混合模型的原理和实现方法，并使用 Scikit-learn 库来实现了一个简单的例子。当然，还有许多高级技术和扩展可以应用于高斯混合模型，比如贝叶斯高斯混合模型和变分推断方法。如果你对此感兴趣，可以进一步学习这些内容。&lt;/p&gt;

&lt;p&gt;希望本文对你理解高斯混合模型有所帮助！&lt;/p&gt;
</description>
        <pubDate>Tue, 28 Mar 2023 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2023/03/28/%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3/</link>
        <guid isPermaLink="true">http://localhost:4000/2023/03/28/%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3/</guid>
        
        <category>notes</category>
        
        
        <category>笔记</category>
        
      </item>
    
      <item>
        <title>论文笔记</title>
        <description>&lt;h1 id=&quot;论文笔记&quot;&gt;论文笔记&lt;/h1&gt;

&lt;h3 id=&quot;题目&quot;&gt;题目:&lt;/h3&gt;

&lt;h3 id=&quot;age-invariant-training-for-end-to-end-child-speech-recognition-using-adversarial-multi-task-learning&quot;&gt;Age-Invariant Training for End-to-End Child Speech Recognition using Adversarial Multi-Task Learning&lt;/h3&gt;

&lt;h3 id=&quot;论文主要研究目的&quot;&gt;论文主要研究目的:&lt;/h3&gt;

&lt;p&gt;1.我们提出了一个基于对抗性多任务学习的端到端语音识别系统声学模型的年龄不变训练框架。此外，我们还&lt;strong&gt;使用年龄信息来区分儿童和成人领域，从而迫使声学模型学习年龄不变特征.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;2.我们进一步表明，使用对抗性多任务学习不一定被视为传统特征空间适应方法的替代品，而应将两者一起使用以获得最佳性能。&lt;/p&gt;

&lt;h3 id=&quot;模型特征&quot;&gt;模型特征:&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/Users/haoxu/Desktop/截屏2022-10-30 11.24.40.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;1.首先确定的是,这是一个声学模型,不是平时所说的语言模型.&lt;/p&gt;

&lt;p&gt;2.在同时训练儿童和成人语音的同时，同时训练了一个鉴别模型，以根据声学模型最后一层的特征来估计说话者的年龄。&lt;/p&gt;

&lt;p&gt;3.定义了一个对抗性损失，这迫使声学模型的特征提取只提取年龄不变特征。&lt;/p&gt;

&lt;p&gt;4.在这项工作中,使用一个简单的基于CTC的时间延迟神经网络工作（TDNN），带有字母（字素）作为目标令牌。&lt;/p&gt;

&lt;h3 id=&quot;implementation-details&quot;&gt;Implementation details&lt;/h3&gt;

&lt;p&gt;Mel Spectrogram Features:&lt;/p&gt;

&lt;p&gt;从音频中提取梅尔谱图特征，使用64个滤波器组。然后使用每个单独的特征通道和话语的平均值和方差对特征进行归一化。在训练过程中，我们使用SpecAugment[32]频率和时间掩蔽增强数据。对于每个语音，我们应用两个频率和时间掩模，大小为6个特征通道，分别为时间步长。
对于基于f0的频率归一化[15]，我们提取kaldi-pitch-features[33]。除了每一帧的音高，这些还提供了一种可能性，即该帧是否包含语音。我们通过这个发声概率来衡量每一帧的音高，从而计算出每一个发音的平均值f0。在计算Mel-filterbank特征之前，我们像[15]一样对语音频谱进行扭曲。&lt;/p&gt;

&lt;p&gt;Enocder network:&lt;/p&gt;

&lt;p&gt;对于编码器网络，我们使用10层TDNN。每个层的内核大小为11，膨胀为1，有512个内核。&lt;/p&gt;

&lt;p&gt;Discriminator network:&lt;/p&gt;

&lt;p&gt;分辨器网络由一个核大小为11的1-D卷积、1的扩张和3的步幅组成，其次是在时间维度上的平均池和两个64个神经元的完全连接层。输出通过sigmoid映射到0到1之间的值。&lt;/p&gt;

&lt;p&gt;ASR Decoder Network:&lt;/p&gt;

&lt;p&gt;asr译码器网络只是一个1维卷积层，其内核大小为1，后面是softmax。由于我们不使用语言模型，它的输出使用贪婪的CTC解码。除输出层外，所有网络中的每一层都跟随一个批归一化[34]和一个ReLU非线性。我们使用PyTorch[35]实现所有模型。&lt;/p&gt;

&lt;h3 id=&quot;题目domain-adversarial-training-of-neural-networks&quot;&gt;题目:Domain-Adversarial Training of Neural Networks&lt;/h3&gt;

&lt;h3 id=&quot;目的&quot;&gt;目的:&lt;/h3&gt;

&lt;p&gt;我们为领域适应引入了一种新的表示学习方法，其中培训和测试时间的数据来自类似但不同的分布。一个重要的例子是在合成或半合成图像上训练图像分类器，这些图像可能大量并完全标记，但不可避免地具有与真实图像不同的分布.另一个例子是书面评论中的情绪分析，其中人们可能为一种类型的产品（例如电影）的评论标记了数据，同时需要对其他产品（例如书籍）的评论进行分类。&lt;/p&gt;

&lt;h3 id=&quot;实现方法&quot;&gt;实现方法:&lt;/h3&gt;

&lt;p&gt;我们表明，这种适应行为几乎可以在任何前馈模型中实现，方法是用很少的标准层和新的梯度反转层来增强它.&lt;/p&gt;

&lt;p&gt;我们的目标是将域适应嵌入到学习表示过程中，以便最终的分类决策基于对域变化具有歧视性且不变性的特征，即在源域和目标域中具有相同或非常相似的分布。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/Users/haoxu/Desktop/截屏2022-10-31 22.19.21.png&quot; alt=&quot;截屏2022-10-31 22.19.21&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 24 Mar 2023 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2023/03/24/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</link>
        <guid isPermaLink="true">http://localhost:4000/2023/03/24/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</guid>
        
        <category>notes</category>
        
        
        <category>笔记</category>
        
      </item>
    
      <item>
        <title>Hello world!</title>
        <description>&lt;p&gt;Hello there!&lt;/p&gt;

&lt;p&gt;This is my first blog on my blog &lt;a href=&quot;http://www.oukohou.wang/&quot;&gt;site&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;That’s all.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
   &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Hi, &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;I&apos;m oukohou&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;regards.&lt;/p&gt;
&lt;h4 align=&quot;right&quot;&gt;oukohou.&lt;/h4&gt;

</description>
        <pubDate>Tue, 28 Aug 2018 19:42:35 +0800</pubDate>
        <link>http://localhost:4000/2018/08/28/Hello-world!/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/08/28/Hello-world!/</guid>
        
        <category>hello</category>
        
        <category>diary</category>
        
        
        <category>日志</category>
        
      </item>
    
  </channel>
</rss>
